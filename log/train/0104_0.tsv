epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.7436931397816906	0.4958946066706077	0.7490247479132026	0.838369234479397
1	0.5824786478934223	0.6516241238492987	0.807215901510544	0.8069825765309041
2	0.5234779665119027	0.485204744193217	0.8274599513359403	0.8554499646102425
3	0.5182038614398813	0.511325502930128	0.8281266513135169	0.8286321354030961
4	0.4106410689447841	0.3536810129880905	0.8650288571287318	0.8781509100791736
5	0.37071227923239747	0.3364036908454221	0.8765598014634038	0.8859803036642159
6	0.34071824944590867	0.34398125687047193	0.8862615731106194	0.8873648870633194
7	0.3338832406352644	0.318336633115035	0.8879961395488587	0.891182493457551
8	0.3118145880429712	0.3133151034784058	0.896892959055237	0.890679378392073
9	0.2894799836592315	0.31062571898750635	0.9024702784585712	0.8877731084937559
10	0.28109772398251376	0.3207808036114211	0.9061330495598412	0.8906052029766887
11	0.2793633240032686	0.3171615620427158	0.9049716609846181	0.8913261952444902
12	0.28121675322317097	0.3072865782710521	0.9075997198448325	0.8937231429406951
13	0.2758912739688403	0.3141495665616315	0.9070352700012055	0.8883115287709741
14	0.26926689627644135	0.3186203411415867	0.9107442543970572	0.8883994102753117
15	0.281731009095499	0.31566853464945505	0.9060287989696434	0.8888524078174487
16	0.2795392777209413	0.3150321544836397	0.9072349468093244	0.8913770099226911
17	0.27795337830504324	0.31155497471437504	0.9081355338969812	0.8941714751485926
18	0.2717804089188576	0.30899727012476197	0.9097576593418252	0.89482500192036
19	0.274957182498215	0.3184601962161453	0.9088972427000712	0.8883401892045305
20	0.271803361978637	0.3276114370268972	0.9096810633227834	0.8881900692828575
21	0.2721787399931313	0.3191673375119496	0.9082741136224292	0.8900488853092681
22	0.26860789042221356	0.31159393934775953	0.90919987793837	0.8894054207441354
