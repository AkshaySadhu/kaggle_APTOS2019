epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.66476821862971	1.1044474218202673	0.7923393445423002	0.7995310677509735
1	0.45701365626376605	0.6819883675678916	0.8520002152331725	0.7977305205409666
2	0.3960990025864347	1.0524091506781785	0.8707069188582195	0.8315037113661088
3	0.4140535786990886	0.5633315563849781	0.8817781198536181	0.8760594409677712
4	0.29804088380795135	0.22281831697277402	0.9041417773910851	0.9244338074600776
5	0.26798202856646286	0.22369910400036885	0.9110996324210018	0.9217746390009183
6	0.24725977829455034	0.21584770200855058	0.9201851936631691	0.9191637582398029
7	0.2507305703247371	0.22684736383835907	0.9181927493951079	0.9162667518367718
8	0.22752066809967483	0.21370225877541563	0.9260305447569698	0.9290080364770087
9	0.21884899046879425	0.210757988869496	0.9306348016868501	0.9276267883209222
10	0.2106797348545945	0.20774206482683835	0.9274023454975097	0.9327355326958807
11	0.20589125655470011	0.2088299658473419	0.9303958030115811	0.9263144927595182
12	0.20410422472607181	0.19509024039396775	0.9342470381597702	0.9333388313324947
13	0.24062442745122573	0.20615612043310766	0.9304513849657906	0.9317909478956806
14	0.20009691808777658	0.19860682328758034	0.9310169608662434	0.9317900614053731
15	0.1998894946426963	0.20636032590561587	0.9291567380735596	0.934288296588147
16	0.19940158351243514	0.19926116826093715	0.9329929710192	0.9262102051155952
17	0.20020825824821772	0.2118929493362489	0.9327549451244824	0.9297663990188375
18	0.20657252424153622	0.21575220917230067	0.9323013838204199	0.930805615834739
19	0.20357931056059897	0.21218502302856548	0.9308709716274791	0.9279952577203184
20	0.23406016830678866	0.1975320771984432	0.9330755319701648	0.9322783194767968
21	0.2116948897373336	0.20897162446509238	0.9340119915526944	0.930876005376399
22	0.21610322505053456	0.21065827094666337	0.9299311712636675	0.9213241688071289
