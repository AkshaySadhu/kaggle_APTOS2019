epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.642666281565376	0.4314932881490044	0.8032767603754155	0.8574994717193773
1	0.4480473814613145	0.4680989242118338	0.8544247859936838	0.8432464346176578
2	0.3455468602478504	0.5399500546248063	0.885387499797729	0.8504117699736853
3	0.33691995671909786	0.290274473959985	0.8827580281446689	0.9003266975886607
4	0.26319271577117237	0.22878076945957931	0.9135362078692382	0.9188910370155579
5	0.24105467946956988	0.2267981346534646	0.9154764173531063	0.9198176522883211
6	0.22315633139046637	0.2286340788654659	0.9234644355163071	0.9167613908859682
7	0.22077112887864528	0.22657567618981653	0.9265325524320306	0.9165358654915354
8	0.20553028178603752	0.22375647011010544	0.9323085516257035	0.9170324660953907
9	0.19738070253768694	0.22006775341604068	0.9359745408509832	0.9241493026987873
10	0.18715801223626602	0.2190285814197167	0.9374286619453683	0.9246395440935661
11	0.1951685863263581	0.21485601786686026	0.932704653526246	0.9268352927045074
12	0.18786284959186678	0.2068378909126572	0.9325090916720158	0.9284198827458808
13	0.18646820820868015	0.21405117238021415	0.9351213889739842	0.9251778753176099
14	0.18717002224825	0.2198804715729278	0.9387138244370756	0.9191944509497324
15	0.18811668617569882	0.22325623910064282	0.9382725980484006	0.9216515080845771
16	0.1834655121454726	0.22462683494972147	0.9367767640862283	0.9190595835348244
17	0.181580295988723	0.22772427810275037	0.9403169640792589	0.9198213727774671
18	0.19295012776780388	0.219214194494745	0.9350947879311756	0.9209593067076868
19	0.18631779325559086	0.22492222552714142	0.9361890516374936	0.9170218769793346
20	0.19674319891340059	0.21442902703648029	0.9321855615719895	0.9248316581822316
21	0.1902737436087235	0.2166489448560321	0.9374650682457196	0.9219196217973755
22	0.18433119405222975	0.22229014142699863	0.9402522221247962	0.9199846413611187
