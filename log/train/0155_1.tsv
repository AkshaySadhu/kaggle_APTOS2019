epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.8904004861960316	0.731218307103851	0.6739916368695309	0.7454018157318201
1	0.7210846201027974	0.6599400040441732	0.732323598322463	0.7675186186096886
2	0.6507283493065008	0.6653681843735204	0.764771457993942	0.7528205282277864
3	0.6440962824490991	0.5842242931605934	0.7698177644935419	0.7874378645905296
4	0.5227114647479341	0.48637044888207603	0.8125759677535735	0.8200709803325829
5	0.48426317541611075	0.4756979883585349	0.8253083910470765	0.8214810647235955
6	0.45105533434612916	0.47100510263047873	0.8388889425227464	0.8314822856413278
7	0.4448153452191613	0.46295967570443797	0.8398414518718393	0.8287153892844342
8	0.4139648300438824	0.4975169803889579	0.8520715927434261	0.8248160497707089
9	0.3977573653406436	0.4567384939350947	0.8579804298707027	0.8314154136143342
10	0.39158168501488055	0.43330443390206513	0.8606343047527285	0.8424573221422756
11	0.3867130856407751	0.4488998032007874	0.8617185444629016	0.836545720019288
12	0.3857811232567719	0.4460056566674779	0.8622532912680675	0.835991453173311
13	0.38115768584579524	0.44281213997118635	0.8635681674086302	0.8430501712850551
14	0.3789568478518193	0.440538522811021	0.864073374457222	0.8395875577881522
15	0.3764783722708131	0.44568907781584777	0.8641123894901204	0.8358272843866377
16	0.3799356061707039	0.4452043900261679	0.8642620993981969	0.8374259402012919
17	0.3752505457452913	0.4606421052720017	0.866308961385474	0.8304014512930563
18	0.37178919169277247	0.4591762850083823	0.8671288536022859	0.8294463236036114
19	0.3756722941773363	0.45336850268474094	0.8668828942156317	0.8347374671380496
20	0.372529164454577	0.4545812017986284	0.8663956565833799	0.8383155325737793
