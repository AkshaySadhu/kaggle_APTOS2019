epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.845826706484608	0.5791131102520487	0.7009630104812068	0.8290690404521688
1	0.553364186183266	0.4998125991095667	0.8331810501746869	0.8775097549359558
2	0.5111038346329461	0.4767383168572965	0.8568421724515178	0.8862513190501884
3	0.440893951965415	0.4711483095003211	0.8872040289431667	0.8898060236492359
4	0.42291256752998935	0.4563791437641434	0.8876570019083281	0.8987032925175124
5	0.3989359632782314	0.4533422220012416	0.9034058647567931	0.9108288003336751
6	0.3700592692779458	0.4543575767589652	0.9118512610949051	0.9034620061669882
7	0.3508609095993249	0.45045362672080164	0.9144432578442611	0.8905074800404411
8	0.3258509486913681	0.4680318832397461	0.9239728571079243	0.9028386120067485
9	0.3065916448831558	0.49135334077088727	0.9296535432116788	0.9070748855610478
10	0.28763952640735585	0.4408678085259769	0.9292019770496848	0.9126327257172647
11	0.26590901985764503	0.4814188920933267	0.9329186201772879	0.8903021803286308
12	0.26660830179310363	0.49377449115981226	0.9364372711783577	0.8913577600704139
13	0.23510951540716316	0.4906084848486859	0.9505367525101036	0.9072623008107742
14	0.21668206762684428	0.5298405004584271	0.9532735838363511	0.9077722549582894
15	0.20148496678018052	0.5148768742447314	0.9503037298879997	0.904417923563003
16	0.2005478242493194	0.5614804502414621	0.9519293393143977	0.9122122957922959
17	0.17211847234031427	0.5278290121451669	0.9547964990488006	0.9011932752575067
18	0.16524850135750097	0.542971399491248	0.9598944155656761	0.9035956470884628
19	0.1575161875428065	0.5391672758952432	0.9637331307128842	0.8878113318517084
20	0.1412605825892609	0.589414862834889	0.9730119893895798	0.8947901930548939
