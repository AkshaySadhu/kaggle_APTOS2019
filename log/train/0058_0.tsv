epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.6964800357818604	1.245634833107824	0.7802258597471092	0.7786020426994266
1	0.5496403861628927	0.7683508046295332	0.8552015181487855	0.8427898473882146
2	0.5165623521999173	0.6856151728526406	0.8724086046528541	0.8475207199710961
3	0.4763801553003166	0.796388473847638	0.8768676122505514	0.8341281721481717
4	0.4219762929107832	0.4442673004839731	0.8925035480472423	0.9023910019380076
5	0.40268223295393196	0.44076538733814075	0.9007977716408853	0.9057621276403526
6	0.3697750069524931	0.42227765917778015	0.9084574664800621	0.9103407576424238
7	0.38001785313953523	0.42231877536877344	0.9057070280496097	0.9091980236736721
8	0.35332857687836106	0.40933489410773566	0.9162610044573618	0.9155080508836807
9	0.34301170674355136	0.407094441678213	0.9178034935331874	0.9181639147301099
10	0.34362725095580454	0.3981367161740427	0.9177351602139615	0.9239326878092349
11	0.32643815040912316	0.3842527309189672	0.9210037870834535	0.9188185496291528
12	0.34034681109630543	0.40711314457914105	0.9150038524561956	0.917609924045613
13	0.3398055476338967	0.41221301484367123	0.9208521794103959	0.9145212959342567
14	0.33195054782149586	0.39589482221914374	0.9185872997966298	0.9162813898170367
15	0.3379154524401478	0.4004311477360518	0.9130580392450356	0.9241186506499842
16	0.324132487339818	0.3921273661696393	0.9290468552399952	0.925220470003675
17	0.32260955999726837	0.39920128817143646	0.9234058614227811	0.9091813324835141
18	0.32779166045720165	0.40144969458165375	0.9236398243484798	0.922893952815162
19	0.33624889150909754	0.40115081745645276	0.9160618672272104	0.9182138332616604
20	0.32483699917793274	0.40105410956818127	0.9248359110514524	0.9150602863383799
21	0.3231368236567663	0.3978772370711617	0.9264636476130321	0.9229478976234003
