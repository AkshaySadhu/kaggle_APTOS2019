epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.7349039520258489	0.593645418467729	0.7574428329541472	0.8598242047780603
1	0.5991942177972068	0.5400688745405363	0.8390930401170194	0.8764894581155103
2	0.5423519759560409	0.5521252709238426	0.855324213196016	0.8863216652273962
3	0.5184894279860284	0.6483531351322713	0.8712862077189256	0.8374664368620551
4	0.44040151426325674	0.4327629655599594	0.8931818456987861	0.9100919351135165
5	0.42189650901633763	0.4241617458022159	0.9036288503219062	0.9057611937372839
6	0.39084456848871446	0.430600304318511	0.9101511693538492	0.9091080231361396
7	0.40981845970710984	0.4029149260857831	0.904164469441024	0.9071725288278225
8	0.3778754088865674	0.3906261958181858	0.9168552983919731	0.9146107530651484
9	0.3539150783630169	0.4079839846362238	0.9260948739454833	0.911306069934293
10	0.3529986771552459	0.41200107384635054	0.9205030053160702	0.9099724724019773
11	0.3647940290848846	0.4149960642275603	0.9282697164867988	0.9045446482898911
12	0.3635860800581134	0.40967622042998025	0.9209245254018396	0.9163070408327283
13	0.35023064004338306	0.40594659567527147	0.9241362407956182	0.9086668219021915
14	0.3612690284119352	0.39642744559956633	0.9218656490323085	0.9233558735830953
15	0.3607892571422069	0.41633494651835895	0.9199162000417342	0.9071065646942307
16	0.3498613309196156	0.3939613256117572	0.9327046023031494	0.9123631577110777
17	0.3577757046112548	0.4093812347754188	0.9206599432138116	0.9145226280281185
18	0.3428480039634135	0.41015074531669204	0.9254970826508796	0.908977918785701
