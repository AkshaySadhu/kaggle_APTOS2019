epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.6949673706422681	0.7802026142244753	0.7747799561206872	0.8546530950347511
1	0.5304749998385492	0.6628222012001536	0.8644507374446342	0.8488903382022767
2	0.5055159359522488	0.502004513921945	0.8721234185099979	0.8834591319774017
3	0.4639624305393385	0.6102049111024194	0.8836927956087341	0.8616364391877853
4	0.4052516703048478	0.45772754368574725	0.8972161850286794	0.896514741491506
5	0.37598670241625415	0.415475669114486	0.9135216146124455	0.9115876005529834
6	0.355544224543416	0.40702108002227283	0.9151661304235585	0.9075381345044267
7	0.3619323986703935	0.40561502135318256	0.9154508198424063	0.9067634726326157
8	0.3409701252113218	0.41291131986224133	0.9223638582138516	0.9095492726013162
9	0.3244407004474298	0.3966988960038061	0.9330312386106552	0.9093011237628447
10	0.33080231301162555	0.3977838398321815	0.9273965403995827	0.9097456109121157
11	0.3246272884957168	0.399311477723329	0.9312604446042091	0.9007007072856499
12	0.3282267925855906	0.41212541642396344	0.9211232282364975	0.8940519469142832
13	0.33070483317841654	0.388265504785206	0.9239213920142674	0.9176461118722342
14	0.3163035256869119	0.38241726548775384	0.9253024725336916	0.924967755583914
15	0.3174742427857026	0.3961516702952592	0.9309372224559768	0.9198834137899626
16	0.3107070693665225	0.39401111006736755	0.9305698406535021	0.9036667104744381
17	0.3138391126919052	0.39258849491243775	0.9316638783010467	0.9056184430038181
18	0.31739080729691876	0.40114590525627136	0.929389474987983	0.9154065204500994
19	0.3210225302078154	0.3998467293770417	0.9261775155818227	0.9097163426702161
20	0.3209669577038806	0.416250277472579	0.927600897928248	0.909190284285933
21	0.3254937264744354	0.4013939175916755	0.9243637567059252	0.9082642559486227
22	0.31992083658342774	0.4033283837463545	0.9283035623279403	0.9086376667082139
23	0.3192376722784146	0.39703717082738876	0.9282563193048643	0.9132367113075464
24	0.3214799119564502	0.4029650973237079	0.9298407881539299	0.9037742310122322
