epoch	train_loss	valid_loss	train_qwk	valid_qwk
0	0.6236585542235685	0.4280690842348596	0.8052018580532004	0.8448631624389021
1	0.44965320307275525	0.35225603178791376	0.8549396998622555	0.8705211953988035
2	0.3613632953037386	0.3104878651059192	0.878692855315064	0.9018838715684963
3	0.3329325513509305	0.37534044229465985	0.8896359056067522	0.8676397665458478
4	0.2725281175225973	0.23603619602711304	0.9059292108516777	0.9152694237138416
5	0.2471612581335332	0.23551722599760347	0.9185883213255885	0.9157387260048211
6	0.2299163249604728	0.2393357510799947	0.9254736295781475	0.9181458454151887
7	0.2270178465253633	0.23623822985783868	0.9259925908521532	0.9178636767579046
8	0.21212260408893877	0.22373305001984473	0.9275443014667772	0.9190935080717431
9	0.20129545680854632	0.2294748120981714	0.9315782378037276	0.9144699772937516
10	0.1951233174489892	0.23443985924772595	0.9340916324368171	0.9168218782290278
11	0.20462701757155036	0.2258279466110727	0.9310256192572458	0.9237582021178892
12	0.19716676024963026	0.2100352965619253	0.9360492528948285	0.9213865145161463
13	0.20424572386495446	0.21103902290696683	0.9291441323618572	0.9224843241746834
14	0.20097485945924468	0.22553136588438696	0.9301605990683186	0.9152284856580188
15	0.1971820905075773	0.22106065827867258	0.9339651937025886	0.9248300661900272
16	0.18655959541059058	0.23118147221596344	0.9347939439067331	0.9193572763702718
17	0.19371593435821327	0.23561211416254874	0.9351289614784998	0.9163521233633517
18	0.19964523520320654	0.22095809034679248	0.9324628217860357	0.9188488456879707
19	0.19495701004305613	0.2227495309451352	0.9339333029884411	0.9236772116073733
20	0.20550574281293413	0.22281418611174045	0.9308543782089767	0.9196123546123133
21	0.19993984938153755	0.228216750142367	0.9323463094761265	0.9125307818313969
22	0.19789552271528088	0.2247255062279494	0.9350215369778764	0.9164149598431014
